# March 29 2020
# Concordia University
# COMP 472 Section NN
# Project 2
# By:
# Jason Brennan - 27793928
# Maryam Eskandari - 40065716
# Martin Grezak - 25693810

import sys
import numpy as np
from operator import itemgetter, attrgetter
from enum import Enum
from collections import defaultdict
import time

# An enum class for flagging the language in use
class Language(Enum):
    EU = 0 #BASQUE
    CA = 1 #CATALAN
    GL = 2 #GALICIAN
    ES = 3 #SPANISH
    EN = 4 #ENGLISH
    PT = 5 #PORTUGUESE

class LangModel:
    
    # default constructor
    def __init__(self):
        self.vocabulary = self.getVocabulary()
        self.ngram = self.getNgram()
        self.smoothing = self.getSmoothing()
        self.trainingFile = self.getTrainingFile()
        self.testingFile = self.getTestFile()

        # each language models below will receive a Matrix generated by the vocabulary and n-gram parameters
        # TODO: 
        # convert to dictionary
        self.table = defaultdict()
        if self.ngram == 2 or self.ngram == 3:
            self.table = defaultdict(dict)
        #self.EU = self.generateMatrix(self.ngram, self.vocabulary)
        #self.CA = self.generateMatrix(self.ngram, self.vocabulary)
        #self.GL = self.generateMatrix(self.ngram, self.vocabulary)
        #self.ES = self.generateMatrix(self.ngram, self.vocabulary)
        #self.EN = self.generateMatrix(self.ngram, self.vocabulary)
        #self.PT = self.generateMatrix(self.ngram, self.vocabulary)


    #parameterized constructor
    def __init__(self,vocabulary=-1,ngram=-1,smoothing=0,trainingFile="",testingFile=""):
        self.vocabulary = self.getVocabulary(vocabulary)
        self.ngram = self.getNgram(ngram)
        self.smoothing = self.getSmoothing(smoothing)
        self.trainingFile = self.getTrainingFile(trainingFile)
        self.testingFile = self.getTestFile(testingFile)

        self.table = defaultdict()
        if self.ngram == 2 or self.ngram == 3:
            self.table = defaultdict(dict)

    def getVocabulary(self,vocabulary=-1):

        choice = vocabulary

        if(choice==-1):
            print("Select a number for which vocabulary you would like to use:")
            print("0 : Fold the corpus to lowercase and use only the 26 letters of the alphabet [a-z]")
            print("1 : Distinguish up and low cases and use only the 26 letters of the alphabet [a-z,A-Z]")
            print("2 : Distinguish up and low cases and use all characters accepted by the built-in isalpha() method")
            choice = int(input ("Enter your choice: "))

        switcher = {
            0: self.generateVocabulary(0),
            1: self.generateVocabulary(1),
            2: self.generateVocabulary(2)
            }
        
        return switcher.get(choice,"Invalid selection")

    def getNgram(self,ngram=-1):

        choice = ngram

        if(choice==-1):
            print("Select a number for which size n-gram you would like to use:")
            print("1 : character unigrams")
            print("2 : character bigrams")
            print("3 : character trigrams")
            choice = int(input ("Enter your choice: "))

        switcher = {
            1: 1,
            2: 2,
            3: 3
            }
        
        return switcher.get(choice,"Invalid selection")

    def getSmoothing(self,smoothing=0):

        choice = smoothing

        if(choice==0):

            interrupt = False
            count = 0
                
            while(not interrupt):
                    
                count = count + 1
                    
                choice = float(input ("Enter a smoothing value between 0 and 1 : "))
                    
                if(choice>=0 or choice<=1):
                    interrupt = True
                    
                if(count>3):
                    print("You failed to provide a smoothing value between 0 and 1, program will continue with default value: 0 ")
                    choice==0
                    interrupt = True
        
        return choice

    def getTrainingFile(self,trainingFile=""):

        dataSet = list()
        fileName = trainingFile
        count = 0

        try:
            # read the data into a list
            with open(str(fileName), encoding="utf8") as file:
                dataSet = file.readlines()

        except FileNotFoundError :
            print("File does not exist")
            fileName=""

        if(fileName==""):

            interrupt = False
            count = 0
            while(not interrupt):
                count = count + 1
                fileName = input ("Enter a valid TRAINING file name with the extension : ")
                
                try:
                    # read the data into a list
                    with open(str(fileName), encoding="utf8") as file:
                        dataSet = file.readlines()

                except FileNotFoundError :
                    print("File does not exist")

                
                if(len(dataSet)>0):
                    interrupt = True
                    
                if(count>3):
                    print("You failed to provide a valid TRAINING file, program will use default training dataset")
                    
                    fileName = "training-tweets.txt"

                    # read the data into a list
                    with open(str(fileName), encoding="utf8") as file:
                        dataSet = file.readlines()

                    interrupt = True

        return dataSet


    def getTestFile(self,testFile=""):

        dataSet = list()
        fileName = testFile
        count = 0

        try:
            # read the data into a list
            with open(str(fileName), encoding="utf8") as file:
                dataSet = file.readlines()

        except FileNotFoundError :
            print("File does not exist")
            fileName=""

        if(fileName==""):

            interrupt = False
            count = 0

            while(not interrupt):
                count = count + 1
                fileName = input ("Enter a valid TEST file name with the extension : ")
                
                try:
                    # read the data into a list
                    with open(str(fileName), encoding="utf8") as file:
                        dataSet = file.readlines()

                except FileNotFoundError :
                    print("File does not exist")

                
                if(len(dataSet)>0):
                    interrupt = True
                    
                if(count>3):
                    print("You failed to provide a valid TEST file, program will use default training dataset")
                    
                    fileName = "test-tweets-given.txt"

                        # read the data into a list
                    with open(str(fileName), encoding="utf8") as file:
                        dataSet = file.readlines()

                    interrupt = True

        return dataSet

    def generateVocabulary(self, selection):

        select = selection

        if(select==0):

            dataSet = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x','y','z']
        
        elif (select==1):

            dataSet = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x','y','z','A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z']

        elif(select==2):
            
            fileName = "utf8.txt"
            dataSet = list()

            # read the data into a list
            with open(str(fileName), encoding="utf8") as file:

              while True:
                char = file.read(1)
                if not char:
                  break
                if(char.isalpha and char!=" "):
                    dataSet.append(char)
  
        return dataSet

    def generateMatrix(self):
        size = len(vocabulary)
 
        if(ngram==1):
            newSize = size*1
        elif(ngram==2):
            newSize = size**2
        elif(ngram==3):
            newSize = size**3
        
        return np.zeros(newSize,newSize)

    def generateProbabilityTable(self):
        self.splitTrainingFile()

        # read trainingFile[i][3] character by character
        for line in self.trainingFile:
            self.incrementValues(self.stringToLanguageEnum(line[2]), line[3].lower())

    def initializeTables(self):
        if self.ngram == 1:
            for character in self.vocabulary:
                self.table[(Language.EU, character)] = self.smoothing
                self.table[(Language.CA, character)] = self.smoothing
                self.table[(Language.GL, character)] = self.smoothing
                self.table[(Language.ES, character)] = self.smoothing
                self.table[(Language.EN, character)] = self.smoothing
                self.table[(Language.PT, character)] = self.smoothing
        elif self.ngram == 2:
            for c1 in self.vocabulary:
                for c2 in self.vocabulary:
                    self.table[(Language.EU, c1)][c2] = self.smoothing
                    self.table[(Language.CA, c1)][c2] = self.smoothing
                    self.table[(Language.GL, c1)][c2] = self.smoothing
                    self.table[(Language.ES, c1)][c2] = self.smoothing
                    self.table[(Language.EN, c1)][c2] = self.smoothing
                    self.table[(Language.PT, c1)][c2] = self.smoothing
        elif self.ngram == 3:
            for c1 in self.vocabulary:
                for c2 in self.vocabulary:
                    for c3 in self.vocabulary:
                        self.table[(Language.EU, c1, c2)][c3] = self.smoothing
                        self.table[(Language.CA, c1, c2)][c3] = self.smoothing
                        self.table[(Language.GL, c1, c2)][c3] = self.smoothing
                        self.table[(Language.ES, c1, c2)][c3] = self.smoothing
                        self.table[(Language.EN, c1, c2)][c3] = self.smoothing
                        self.table[(Language.PT, c1, c2)][c3] = self.smoothing


    def splitTrainingFile(self):
        for i in range(len(self.trainingFile)):
            # split the lines in the training file by the first 3 tabs
            self.trainingFile[i] = self.trainingFile[i].split("\t", 3)
            # remove trailing newline character at the end of the tweet
            self.trainingFile[i][3] = self.trainingFile[i][3][0:len(self.trainingFile[i][3])-1]

    def stringToLanguageEnum(self, str):
        if str == "eu":
            return Language.EU
        elif str == "ca":
            return Language.CA
        elif str == "gl":
            return Language.GL
        elif str == "es":
            return Language.ES
        elif str == "en":
            return Language.EN
        elif str == "pt":
            return Language.PT

    def existsInVocab(self, str):
        for character in str:
            if character not in self.vocabulary:
                return False
        return True

    def incrementValues(self, language, str):
        substringLength = 0

        if self.ngram == 1:
            substringLength = 1
            for i in range(len(str) - substringLength - 1):
                substr = str[i:(i + substringLength)]
                if self.existsInVocab(substr):
                    self.table[(language, substr)] += 1

        elif self.ngram == 2:
            substringLength = 2
            for i in range(len(str) - substringLength - 1):
                substr = str[i:(i + substringLength)]
                if self.existsInVocab(substr):
                    self.table[(language, substr[0])][substr[1]] += 1

        elif self.ngram == 3:
            substringLength = 3
            for i in range(len(str) - substringLength - 1):
                substr = str[i:(i + substringLength)]
                if self.existsInVocab(substr):
                    self.table[(language, substr[0], substr[1])][substr[2]] += 1
        

#MAIN

test = LangModel(0,1, 0.1, "training-tweets.txt", "test-tweets-given.txt")
test.initializeTables()
test.generateProbabilityTable()

print(test.table)


